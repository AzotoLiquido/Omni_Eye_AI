# Omni Eye AI - Assistente AI Locale

ğŸ¤– Assistente AI completamente locale e privato, senza limiti di utilizzo.

## ğŸŒŸ Caratteristiche

- âœ… **Completamente Locale**: Nessun dato esce dal tuo PC
- âœ… **Gratuito e Illimitato**: Nessun token o costo di utilizzo
- âœ… **Memoria Conversazioni**: L'AI ricorda le chat precedenti
- âœ… **Analisi Documenti**: Carica e analizza file PDF, TXT, DOCX
- âœ… **Interfaccia Web Modern**: GUI intuitiva e bella
- âœ… **Modelli Potenti**: LLaMA, Mistral, e altri modelli open source

## ğŸ“‹ Requisiti

- Python 3.8+
- Ollama (per i modelli AI)
- 8GB+ RAM (16GB consigliato)
- 10GB+ spazio disco per i modelli

## ğŸš€ Installazione Rapida

1. **Installa Ollama** (se non l'hai giÃ ):
   - Scarica da: https://ollama.ai/download
   - Oppure esegui: `winget install Ollama.Ollama`

2. **Installa dipendenze Python**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Scarica un modello AI** (prima volta):
   ```bash
   ollama pull llama3.2
   ```

4. **Avvia l'applicazione**:
   ```bash
   python start.py
   ```

5. **Apri il browser** e vai su: http://localhost:5000

## ğŸ¯ Modelli Consigliati

- `llama3.2` (3B) - Veloce, buono per PC normali
- `mistral` (7B) - Ottimo bilanciamento qualitÃ /velocitÃ 
- `llama3.1` (8B) - Molto intelligente
- `codellama` - Specializzato per codice

Per cambiare modello, modifica `config.py`

## ğŸ“ Struttura Progetto

```
Omni_Eye_AI/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ static/      # CSS, JS, immagini
â”‚   â”œâ”€â”€ templates/   # HTML templates
â”‚   â””â”€â”€ main.py      # Backend Flask
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ai_engine.py    # Motore AI Ollama
â”‚   â”œâ”€â”€ memory.py       # Sistema memoria
â”‚   â””â”€â”€ document_processor.py  # Analisi documenti
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ conversations/  # Chat salvate
â”‚   â””â”€â”€ uploads/       # File caricati
â”œâ”€â”€ config.py          # Configurazione
â”œâ”€â”€ requirements.txt   # Dipendenze
â””â”€â”€ start.py          # Script avvio

```

## ğŸ’¡ Utilizzo

1. **Chat Normale**: Scrivi messaggi come in ChatGPT
2. **Carica Documenti**: Click su ğŸ“ per analizzare file
3. **Cronologia**: Accedi alle conversazioni passate
4. **Nuova Chat**: Inizia conversazione fresca

## ğŸ”’ Privacy

Tutto rimane sul tuo PC:
- Modelli AI scaricati localmente
- Conversazioni salvate in `data/conversations/`
- Documenti processati in `data/uploads/`
- Nessuna connessione a server esterni (dopo download modelli)

## âš™ï¸ Configurazione

Modifica `config.py` per:
- Cambiare modello AI
- Regolare temperatura (creativitÃ )
- Cambiare porta server
- Personalizzare prompt di sistema

## ğŸ†˜ Risoluzione Problemi

**Ollama non trovato?**
- Assicurati che Ollama sia installato e in esecuzione
- Controlla: `ollama list`

**Modello non trovato?**
- Scarica: `ollama pull llama3.2`

**Errori di memoria?**
- Usa un modello piÃ¹ piccolo (llama3.2:1b)
- Chiudi altre applicazioni

## ğŸ“ Licenza

MIT - Usa liberamente!
